{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement faiss-gpu (from versions: none)\n",
      "ERROR: No matching distribution found for faiss-gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 13\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (AutoTokenizer, AutoModelForSequenceClassification,\n\u001b[0;32m     10\u001b[0m                           T5ForConditionalGeneration, AutoConfig,\n\u001b[0;32m     11\u001b[0m                           TrainingArguments, Trainer, pipeline)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mevaluate\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Check CUDA\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'datasets'"
     ]
    }
   ],
   "source": [
    "#%% Setup Environment\n",
    "%pip install transformers[torch] faiss-gpu datasets sentence-transformers accelerate -q\n",
    "import torch\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import (AutoTokenizer, AutoModelForSequenceClassification,\n",
    "                          T5ForConditionalGeneration, AutoConfig,\n",
    "                          TrainingArguments, Trainer, pipeline)\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from datasets import Dataset\n",
    "import evaluate\n",
    "\n",
    "# Check CUDA\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Data Preparation\n",
    "def preprocess_data():\n",
    "    # Load dataset\n",
    "    df = pd.read_csv(\"recovery-news-data.csv\")\n",
    "    \n",
    "    # Convert to 3-tier trust score\n",
    "    def calculate_trust(row):\n",
    "        if row['news_guard_score'] >= 75 and row['mbfc_level'] == 'High':\n",
    "            return 2  # High trust\n",
    "        elif row['news_guard_score'] >= 50 or row['mbfc_level'] in ['Mixed', 'Mostly Factual']:\n",
    "            return 1  # Medium trust\n",
    "        else:\n",
    "            return 0  # Low trust\n",
    "    \n",
    "    df['trust_tier'] = df.apply(calculate_trust, axis=1)\n",
    "    \n",
    "    # Split data\n",
    "    train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['trust_tier'])\n",
    "    return train_df, val_df, df\n",
    "\n",
    "train_df, val_df, full_df = preprocess_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Trustworthiness Classifier\n",
    "class TrustModelTrainer:\n",
    "    def __init__(self):\n",
    "        self.model_name = \"bert-base-uncased\"\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "        self.config = AutoConfig.from_pretrained(self.model_name, num_labels=3)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            self.model_name, config=self.config).to(device)\n",
    "        \n",
    "    def _prepare_dataset(self, texts, labels):\n",
    "        encodings = self.tokenizer(texts, truncation=True, padding=True, max_length=256)\n",
    "        return Dataset.from_dict({\n",
    "            'input_ids': encodings['input_ids'],\n",
    "            'attention_mask': encodings['attention_mask'],\n",
    "            'labels': labels\n",
    "        })\n",
    "    \n",
    "    def train(self, train_texts, train_labels, val_texts, val_labels):\n",
    "        # Convert to HuggingFace datasets\n",
    "        train_dataset = self._prepare_dataset(train_texts, train_labels)\n",
    "        val_dataset = self._prepare_dataset(val_texts, val_labels)\n",
    "\n",
    "        # Training arguments\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir='./results',\n",
    "            num_train_epochs=4,\n",
    "            per_device_train_batch_size=32,\n",
    "            per_device_eval_batch_size=64,\n",
    "            fp16=True,\n",
    "            evaluation_strategy=\"epoch\",\n",
    "            save_strategy=\"epoch\",\n",
    "            logging_dir='./logs',\n",
    "            report_to=\"none\",\n",
    "            gradient_accumulation_steps=2,\n",
    "            learning_rate=2e-5,\n",
    "            weight_decay=0.01,\n",
    "        )\n",
    "\n",
    "        # Metrics\n",
    "        f1_metric = evaluate.load(\"f1\")\n",
    "\n",
    "        def compute_metrics(eval_pred):\n",
    "            logits, labels = eval_pred\n",
    "            predictions = np.argmax(logits, axis=-1)\n",
    "            return f1_metric.compute(\n",
    "                predictions=predictions, references=labels, average=\"weighted\")\n",
    "\n",
    "        # Trainer\n",
    "        trainer = Trainer(\n",
    "            model=self.model,\n",
    "            args=training_args,\n",
    "            train_dataset=train_dataset,\n",
    "            eval_dataset=val_dataset,\n",
    "            compute_metrics=compute_metrics,\n",
    "        )\n",
    "\n",
    "        # Train\n",
    "        trainer.train()\n",
    "        return self.model\n",
    "\n",
    "# Initialize and train\n",
    "trust_trainer = TrustModelTrainer()\n",
    "trust_model = trust_trainer.train(\n",
    "    train_df['body_text'].tolist(),\n",
    "    train_df['trust_tier'].tolist(),\n",
    "    val_df['body_text'].tolist(),\n",
    "    val_df['trust_tier'].tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% FAISS Retriever\n",
    "class FAISSRetriever:\n",
    "    def __init__(self, model_name=\"sentence-transformers/all-mpnet-base-v2\"):\n",
    "        self.encoder = SentenceTransformer(model_name).to(device)\n",
    "        self.index = None\n",
    "        self.metadata = []\n",
    "        \n",
    "    def build_index(self, documents, trust_scores, batch_size=512):\n",
    "        # Convert documents to embeddings\n",
    "        embeddings = []\n",
    "        for i in tqdm(range(0, len(documents), batch_size)):\n",
    "            batch = documents[i:i+batch_size]\n",
    "            embeds = self.encoder.encode(batch, convert_to_tensor=True,\n",
    "                                       device=device, show_progress_bar=False)\n",
    "            embeddings.append(embeds.cpu().numpy())\n",
    "            \n",
    "        embeddings = np.concatenate(embeddings)\n",
    "        \n",
    "        # Build FAISS index\n",
    "        self.index = faiss.IndexFlatIP(embeddings.shape[1])\n",
    "        self.index.add(embeddings.astype(np.float32))\n",
    "        self.trust_scores = np.array(trust_scores)\n",
    "        \n",
    "    def search(self, query, k=10, trust_weight=0.4):\n",
    "        query_embed = self.encoder.encode([query], convert_to_tensor=True,\n",
    "                                        device=device).cpu().numpy()\n",
    "        \n",
    "        # Search with FAISS\n",
    "        distances, indices = self.index.search(query_embed.astype(np.float32), k*3)\n",
    "        \n",
    "        # Rerank with trust scores\n",
    "        results = []\n",
    "        for idx, score in zip(indices[0], distances[0]):\n",
    "            trust_score = self.trust_scores[idx] / 2  # Normalize 0-2 to 0-1\n",
    "            combined_score = (1 - trust_weight) * score + trust_weight * trust_score\n",
    "            results.append((idx, combined_score))\n",
    "            \n",
    "        # Return top-k sorted\n",
    "        return sorted(results, key=lambda x: x[1], reverse=True)[:k]\n",
    "\n",
    "# Build index\n",
    "retriever = FAISSRetriever()\n",
    "retriever.build_index(\n",
    "    full_df['body_text'].tolist(),\n",
    "    full_df['trust_tier'].values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Generator Component\n",
    "class TrustAwareGenerator:\n",
    "    def __init__(self, model_name=\"t5-base\"):\n",
    "        self.model = T5ForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.trust_model = trust_model\n",
    "        self.trust_tokenizer = trust_trainer.tokenizer\n",
    "        \n",
    "    def generate(self, query, context_docs, max_length=200):\n",
    "        # Prepare context\n",
    "        context = \"\\n\".join(context_docs[:3])\n",
    "        \n",
    "        # Prepare input\n",
    "        input_text = f\"answer: {query} context: {context}\"\n",
    "        input_ids = self.tokenizer(\n",
    "            input_text, return_tensors=\"pt\", truncation=True, max_length=512\n",
    "        ).input_ids.to(device)\n",
    "        \n",
    "        # Generate\n",
    "        outputs = self.model.generate(\n",
    "            input_ids,\n",
    "            max_length=max_length,\n",
    "            num_beams=4,\n",
    "            early_stopping=True,\n",
    "            repetition_penalty=2.5,\n",
    "            temperature=0.7,\n",
    "        )\n",
    "        \n",
    "        return self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Initialize generator\n",
    "generator = TrustAwareGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Evaluation Metrics\n",
    "def evaluate_system(val_queries, k=5):\n",
    "    precision_metric = evaluate.load(\"precision_at_k\")\n",
    "    recall_metric = evaluate.load(\"recall_at_k\")\n",
    "    \n",
    "    results = []\n",
    "    for query in tqdm(val_queries[:100]):  # Sample 100 for evaluation\n",
    "        retrieved = retriever.search(query, k=k)\n",
    "        doc_ids = [idx for idx, _ in retrieved]\n",
    "        trust_scores = full_df.iloc[doc_ids]['trust_tier'].values\n",
    "        \n",
    "        # Calculate metrics\n",
    "        precision = np.mean([1 if s >= 1 else 0 for s in trust_scores])\n",
    "        recall = np.sum([1 if s >= 1 else 0 for s in trust_scores]) / len(trust_scores)\n",
    "        \n",
    "        results.append({\"precision\": precision, \"recall\": recall})\n",
    "    \n",
    "    avg_precision = np.mean([r[\"precision\"] for r in results])\n",
    "    avg_recall = np.mean([r[\"recall\"] for r in results])\n",
    "    print(f\"Precision@{k}: {avg_precision:.2f}, Recall@{k}: {avg_recall:.2f}\")\n",
    "\n",
    "# Example evaluation\n",
    "evaluate_system([\"COVID vaccine efficacy\", \"Climate change impacts\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% End-to-End Pipeline\n",
    "def full_pipeline(query, trust_threshold=1):\n",
    "    # Retrieve documents\n",
    "    retrieved = retriever.search(query)\n",
    "    doc_ids = [idx for idx, _ in retrieved]\n",
    "    docs = full_df.iloc[doc_ids]['body_text'].tolist()\n",
    "    \n",
    "    # Filter by trust\n",
    "    filtered_docs = [doc for doc, score in zip(docs, full_df.iloc[doc_ids]['trust_tier']) \n",
    "                   if score >= trust_threshold]\n",
    "    \n",
    "    # Generate answer\n",
    "    if len(filtered_docs) == 0:\n",
    "        return \"No trustworthy sources found\"\n",
    "    \n",
    "    return generator.generate(query, filtered_docs)\n",
    "\n",
    "# Example usage\n",
    "result = full_pipeline(\"What are the long-term effects of COVID-19 vaccines?\")\n",
    "print(\"Generated Answer:\", result)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
